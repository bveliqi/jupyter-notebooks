{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Tutorial Reihe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #4 - Das erste eigene Neuronale Netz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeinNetz(\n",
      "  (lin1): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (lin2): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Jedes Netz sollte grob diesen Aufbau haben!\n",
    "\n",
    "class MeinNetz(nn.Module):\n",
    "    def __init__(self):\n",
    "        # jede einzelne Schicht im Model ist eine einzelne Variable hier\n",
    "        super(MeinNetz, self).__init__()\n",
    "        self.lin1 = nn.Linear(10, 10) # Linear is eine Fkt. die aufgerufen werden kann\n",
    "        self.lin2 = nn.Linear(10, 10)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x) # <-- letzte immer ohne eine Aktivierungsfkt. damit sicher ein Output zurück kommt\n",
    "        return x\n",
    "        \n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        # braucht man damit nn.Module was gescheites ausgibt in der Konsole\n",
    "        size = x.size()[1:]\n",
    "        num = 1\n",
    "        for i in size:\n",
    "            num *= i\n",
    "        return num\n",
    "        \n",
    "model = MeinNetz()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #5 - Das Netz füttern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.2286  1.2073 -1.2697  1.2511  0.9695  1.2869 -0.5863 -2.1078 -1.1088 -1.3281\n",
      "-1.5167  0.4627 -0.9039  0.2372  0.8171  0.9615  0.2399 -1.0104 -0.0789  0.9825\n",
      "-0.7906  1.9804 -1.4758  2.2157 -0.6175  0.0839 -0.4624  0.0973 -0.3901 -0.8203\n",
      " 0.1064  1.1078 -0.2464 -0.0435 -0.8691  0.8513 -1.3851 -0.0106 -0.6182  0.8181\n",
      " 2.1930  1.3023  0.2176  1.8768 -0.9847  0.4382 -0.8564  0.0061 -0.3072 -0.9173\n",
      "-2.1286  0.5561  0.5116  0.3655  0.5223  1.6007  0.0558  0.7642 -1.8287 -0.1110\n",
      " 2.5283 -0.2376 -1.3060  0.7654 -1.2156 -0.1949 -1.1956 -2.5344  0.6591 -0.9512\n",
      " 1.5505  0.6606 -0.2800  0.5978 -1.1864  1.1231 -0.0647  0.4099 -1.3043  1.7683\n",
      "-1.3894 -0.1509  0.5991 -0.8540  0.7090 -0.4501  0.6290 -1.7021 -0.1623  0.0355\n",
      "-0.5412  0.1359  0.6589 -0.2145 -0.4294  0.1719  0.9223 -0.8185  0.8332  0.1493\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(10,10))\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.0370  0.2835 -0.0014  0.0648  0.0294 -0.2380  0.2325 -0.5592  0.0855  0.0164\n",
      "-0.1272 -0.1228 -0.0585  0.0432 -0.2186 -0.0425  0.2936 -0.2009  0.0710  0.1004\n",
      " 0.0436  0.0139 -0.0008 -0.0007 -0.2896 -0.2504  0.3285 -0.3080 -0.0437 -0.0370\n",
      "-0.2315 -0.1255  0.1466  0.1778 -0.1936  0.0810  0.1996 -0.1474 -0.0159  0.0599\n",
      " 0.2059  0.1375  0.7084  0.3293 -0.4096 -0.4260  0.2012 -0.1996 -0.0290 -0.3456\n",
      "-0.0734 -0.1073 -0.3677 -0.2772 -0.3441  0.0108  0.4234  0.0306 -0.2328 -0.1323\n",
      "-0.4334  0.1542  0.6217  0.3474  0.2127 -0.3321 -0.6054 -0.1135 -0.0822  0.0641\n",
      "-0.2726 -0.2192 -0.0720  0.0167 -0.1749  0.0005  0.1881 -0.0426 -0.0206  0.0147\n",
      "-0.3291 -0.0646  0.2830  0.1020 -0.1809  0.1890  0.0644 -0.2313  0.1125  0.2589\n",
      "-0.3660 -0.2028  0.1508  0.2786 -0.0147 -0.0952 -0.0085 -0.2816  0.2113  0.1432\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = model(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #6 - Das Netz lernen lassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e-09 *\n",
      "  3.4044\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    x = [1,0,0,0,1,0,0,0,1,1] # input\n",
    "    input = Variable(torch.Tensor([x for _ in range(10)]))\n",
    "    # input = input.cuda()\n",
    "    \n",
    "    out = model(input)\n",
    "\n",
    "    x = [0,1,1,1,0,1,1,1,0,0] # target is genau opposite von input, i.e. netz muss lernen jedes bit zu flippen\n",
    "    target = Variable(torch.Tensor([x for _ in range(10)]))\n",
    "    # target = target.cuda()\n",
    "    \n",
    "    # Kriterum wie unser Fehler berechnet werden soll\n",
    "    criterion = nn.MSELoss()\n",
    "    loss = criterion(out, target) # d.h. wir vergleichen das berechnete output mit dem eigentlich Ziel\n",
    "    clear_output(wait=True)\n",
    "    print(loss)\n",
    "    \n",
    "    model.zero_grad() # im gegensatz zu TensorFlow muss bei pytorch die gradienten immer zurücksetzten pro step --> würde zu größeren Lernrate führen als gewollt, wenn ausgelassen\n",
    "    loss.backward() # loss über backprop zurückfließen lassen\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #9 - Handschrifterkennung mit dem MNIST Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST dataset\n",
    "kwargs = {}\n",
    "train_data = torch.utils.data.DataLoader(datasets.MNIST('data', train=True, \n",
    "                                                    download=True, \n",
    "                                                    transform = transforms.Compose([\n",
    "                                                        transforms.ToTensor(), \n",
    "                                                        transforms.Normalize((0.1307,),(0.3081,)) #? \n",
    "                                                    ])),\n",
    "                                    batch_size=64,\n",
    "                                    shuffle=True,\n",
    "                                    **kwargs)\n",
    "\n",
    "test_data = torch.utils.data.DataLoader(datasets.MNIST('data', train=False,\n",
    "                                                    transform = transforms.Compose([\n",
    "                                                        transforms.ToTensor(), \n",
    "                                                        transforms.Normalize((0.1307,),(0.3081,))\n",
    "                                                    ])),\n",
    "                                    batch_size=64,\n",
    "                                    shuffle=True,\n",
    "                                    **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #10 - Handschrifterkennung mit dem MNIST Datensatz - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Netz(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Netz, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv_dropout = nn.Dropout2d() #?\n",
    "        self.fc1 = nn.Linear(320, 60)\n",
    "        self.fc2 = nn.Linear(60, 10)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv_dropout(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29 [29984/60000 (100%)]\tLoss: 2.297858\n"
     ]
    }
   ],
   "source": [
    "model = Netz()\n",
    "# model.cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.8)\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_id, (data, target) in enumerate(train_data): # 64 datenpunkte pro iteration, s. batch_size\n",
    "        # data = data.cuda()\n",
    "        # target = t_arget.cuda()\n",
    "        data = Variable(data)\n",
    "        target = Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        clear_output(wait=True)\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_id * len(data), len(train_data.dataset),\n",
    "            100 * batch_id / len(train_data), loss.data[0]\n",
    "        ))\n",
    "        \n",
    "for epoch in range(1, 30):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #12 - Handschrifterkennung mit dem MNIST Datensatz - Evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    for data. target in test_data:\n",
    "        data = Variable(data, volatile=True)\n",
    "        target = Variable(target)\n",
    "        out = model(data)\n",
    "        loss = nn.CrossEntropyLoss()(out, target)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
